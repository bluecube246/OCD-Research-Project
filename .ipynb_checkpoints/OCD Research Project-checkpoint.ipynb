{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of OCD Rates in College Students 2019 – date\n",
    "#### Research Problem: Increased cases of self-reported Obsessive Compulsive Disorder (OCD) cases amongst students\n",
    "#### Objectives: Identify causes of higher incidence and factors correlated with OCD Methodology: Perform analysis on survey data from American Health Association – National College Health Assessment, to evaluate mental health issue of OCD by utilizing descriptive and inferential statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Upload and Clean SurveyI SurveyII SurveyII</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File SurveyI.csv does not exist: 'SurveyI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd6c93dc5735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTextFileReader1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'SurveyI.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf1List\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTextFileReader1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf1List\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File SurveyI.csv does not exist: 'SurveyI.csv'"
     ]
    }
   ],
   "source": [
    "TextFileReader1 = pd.read_csv(r'SurveyI.csv',error_bad_lines=False,chunksize=1000)\n",
    "\n",
    "df1List = []\n",
    "for df in TextFileReader1:\n",
    "    df1List.append(df)\n",
    "    \n",
    "df1 = pd.concat(df1List,sort=False)\n",
    "df1 = df1.replace(' ',-1)\n",
    "df1 = df1.astype('int64',errors='ignore')\n",
    "df1 = df1.apply(lambda x: x.astype('int64',errors='ignore'))\n",
    "df1 = df1.apply(lambda x: x.astype('float64',errors='ignore') if x.dtype == 'O' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextFileReader2 = pd.read_csv(r'SurveyII.csv',error_bad_lines=False,chunksize=1000)\n",
    "\n",
    "dfList2 = []\n",
    "for df in TextFileReader2:\n",
    "    dfList2.append(df)\n",
    "    \n",
    "df2 = pd.concat(dfList2,sort=False)\n",
    "df2 = df2.replace(' ',-1)\n",
    "df2 = df2.astype('int64',errors='ignore')\n",
    "df2 = df2.apply(lambda x: x.astype('int64',errors='ignore'))\n",
    "df2 = df2.apply(lambda x: x.astype('float64',errors='ignore') if x.dtype == 'O' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextFileReader3 = pd.read_csv(r'SurveyIIInew.csv',error_bad_lines=False,chunksize=1000)\n",
    "\n",
    "dfList3 = []\n",
    "for df in TextFileReader3:\n",
    "    dfList3.append(df)\n",
    "    \n",
    "df3 = pd.concat(dfList3,sort=False)\n",
    "df3 = df3.replace(' ',-1) #updating null values to -1\n",
    "df3 = df3.astype('int64',errors='ignore')\n",
    "df3 = df3.apply(lambda x: x.astype('int64',errors='ignore'))\n",
    "df3 = df3.apply(lambda x: x.astype('float64',errors='ignore') if x.dtype == 'O' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Counts of People reported to have OCD</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Survey I\")\n",
    "print(df1['NQ31B1'].value_counts())\n",
    "print(\"Survey II\")\n",
    "print(df2['NQ31B1'].value_counts())\n",
    "print(\"Survey III\")\n",
    "print(df3['NQ31B1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing Data Points with implausible height weight and BMI</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#height\n",
    "df1['NQ49'] = df1.NQ49_FT * 12 + df1.NQ49_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_bool = ((df1['NQ49'] >= 47.2441) & (df1['NQ49'] <= 82.6772) & (df1['NQ50'] >= 77.16) & (df1['NQ50'] <= 396.832) & (df1['BMI'] >= 16) & (df1['BMI'] <= 65))\n",
    "print(\"Data before trim: \" + str(len(df1)))\n",
    "print(\"Data after trim: \" + str(len(df1[df1_bool])))\n",
    "df1 = df1[df1_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_bool = ((df2['NQ49'] >= 47.2441) & (df2['NQ49'] <= 82.6772) & (df2['NQ50'] >= 77.16) & (df2['NQ50'] <= 396.832) & (df2['BMI'] >= 16) & (df2['BMI'] <= 65))\n",
    "print(\"Data before trim: \" + str(len(df2)))\n",
    "print(\"Data after trim: \" + str(len(df2[df2_bool])))\n",
    "df2 = df2[df2_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_bool = ((df3['NQ49'] >= 47.2441) & (df3['NQ49'] <= 82.6772) & (df3['NQ50'] >= 77.16) & (df3['NQ50'] <= 396.832) & (df3['BMI'] >= 16) & (df3['BMI'] <= 65))\n",
    "print(\"Data before trim: \" + str(len(df3)))\n",
    "print(\"Data after trim: \" + str(len(df3[df3_bool])))\n",
    "df3 = df3[df3_bool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Merge Data Frames</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd = pd.concat([df1,df2,df3],axis=0,sort = True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing columns with more than 10% of null values\n",
    "data_ocd = data_ocd.loc[:, data_ocd.isnull().mean() < .1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Delete Unanswered Responses</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd = data_ocd[data_ocd['NQ31B1'] != -1] #OCD Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Total survey results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd['NQ31B1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>After Deleting Unanswered Responses</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd[data_ocd['HBCU']==-1]['HBCU'] = 0\n",
    "data_ocd[data_ocd['HHE']==-1]['HHE'] = 0\n",
    "data_ocd[data_ocd['HS']==-1]['HS'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create Label for Plot</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ = []\n",
    "k = 0\n",
    "j = 2008\n",
    "for i in range(18,40):\n",
    "    if(k == 0):\n",
    "        label_.append(\"Fall\" + str(j))\n",
    "        k = 1\n",
    "        j += 1\n",
    "    else:\n",
    "        label_.append(\"Spring\" + str(j))\n",
    "        k = 0\n",
    "        \n",
    "label_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>OCD Rate Between Terms</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.2f}%\".format(y_value*100)\n",
    "        #label = str(label * 100) + \"%\"\n",
    "        \n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            va=va)                      # Vertically align label differently for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ocd_ratio(data_ocd):  \n",
    "    \n",
    "    ratio = []\n",
    "    \n",
    "    for x,answer in enumerate(data_ocd.STUDY.value_counts().sort_index(ascending=True).index.values):\n",
    "        data = data_ocd[(data_ocd['STUDY'] == answer)]\n",
    "        ratio.append(data.NQ31B1[(data['NQ31B1'] != 1) & (data['NQ31B1'] != -1)].value_counts().sum() / len(data.NQ31B1))\n",
    "\n",
    "    ocd_plot = pd.DataFrame({'lab':label_, 'val':ratio})\n",
    "    #plt.bar(ocd_plot,label=\"Percent of people who reported OCD\",figsize=(18,6))\n",
    "    ax = ocd_plot.plot.bar(x='lab',y='val',label=\"Percent of people who reported OCD\",figsize=(17,6),color=\"#1f77b4\")\n",
    "    add_value_labels(ax)\n",
    "    \n",
    "    return ocd_plot, ratio\n",
    "\n",
    "ocd_plot, ratio = plot_ocd_ratio(data_ocd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Curve Fitting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendline(data, order=1):\n",
    "    coeffs = np.polyfit(data.index.values, list(data), order)\n",
    "    slope = coeffs[-2]\n",
    "    return float(slope)\n",
    "\n",
    "slope = trendline(pd.Series(ocd_plot['val']))\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "curve = pd.DataFrame({'lab':term, 'val':ratio})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, c, d):\n",
    "    return a*np.exp(-c*x)+d\n",
    "def func2(x, a, b):\n",
    "    return a*x+b\n",
    "popt, pcov = curve_fit(func, term, ratio, p0=(1, 1e-6, 1))\n",
    "xx = np.linspace(0, 20,1000)\n",
    "yy = func(xx, *popt)\n",
    "plt.plot(term,ratio,'ko')\n",
    "plt.plot(xx, yy)\n",
    "popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(x, a, b):\n",
    "    return a*x+b\n",
    "popt, pcov = curve_fit(func2, term, ratio, p0=(1, 2))\n",
    "xx = np.linspace(0, 20,1000)\n",
    "yy = func2(xx, *popt)\n",
    "plt.plot(term,ratio,'ko')\n",
    "plt.plot(xx, yy)\n",
    "popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: A linear fit seems like the correct fit to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "curve['intercept']=1\n",
    "lm=sm.OLS(curve['val'],curve[['intercept','lab']])\n",
    "slr_results = lm.fit()\n",
    "slr_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: B = 0 Year has no effect on OCD rates. \n",
    "\n",
    "H1: B > 0 Year has positive linear relationship with OCD rates. \n",
    "\n",
    "The p value for the is very small. For a one sided test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dickey-Fuller test</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho: Time series is non-stationary\n",
    "\n",
    "H1: Time series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(curve['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = curve['val'].values\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key,value))\n",
    "    \n",
    "if result[0] < result[4][\"5%\"]:\n",
    "    print(\"Reject H0 - Time Series is Stationary\")\n",
    "else:\n",
    "    print(\"Failed to Reject Ho - Time series is Non-Stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Stacked Bar Chart</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd['Treated'] = 2\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == -1,'Treated'] = 0\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == 1,'Treated'] = 0\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == 2,'Treated'] = 1\n",
    "data_ocd.Treated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_value = data_ocd['STUDY'].value_counts(sort=False)\n",
    "pivot_df = data_ocd[data_ocd.Treated != 0].pivot_table(index = ['STUDY'],columns=['Treated'],aggfunc = 'size',observed=True)\n",
    "pivot_df = pivot_df.div(study_value,axis=0)\n",
    "pivot_df = pivot_df.multiply(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_rows = pivot_df.sum(axis=1)\n",
    "normalized_array = pivot_df / sum_of_rows[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pivot_df.plot.bar(stacked=True,figsize=(17,6))\n",
    "ax.set_xticklabels(label_)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "height_prev = np.zeros(22)\n",
    "#print(len(height_prev))\n",
    "#print(height_prev)\n",
    "patch = 0\n",
    "for i in range(1,3):\n",
    "    #print(height_prev)\n",
    "    j = 0\n",
    "    for rec, label in zip(ax.patches,pivot_df[i].round(2).astype(str)): \n",
    "        #print(rec)\n",
    "        height = rec.get_height()\n",
    "        height = ax.patches[patch].get_height()\n",
    "        #print(height,height_prev[j],(height/2 + height_prev[j]))\n",
    "        ax.text(rec.get_x() + rec.get_width() / 2, (height/2 + height_prev[j]), label,\n",
    "               ha = 'center', va='bottom')\n",
    "        #print(height,height_prev[j])\n",
    "        height_prev[j] = height + height_prev[j]\n",
    "        j += 1\n",
    "        patch += 1\n",
    "\n",
    "ax.set_xticklabels(label_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = normalized_array.plot.bar(stacked=True,figsize=(17,6))\n",
    "ax.set_xticklabels(label_)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "height_prev = np.zeros(22)\n",
    "#print(len(height_prev))\n",
    "#print(height_prev)\n",
    "patch = 0\n",
    "for i in range(1,3):\n",
    "    #print(height_prev)\n",
    "    j = 0\n",
    "    for rec, label in zip(ax.patches,normalized_array[i].round(2).astype(str)): \n",
    "        #print(rec)\n",
    "        height = rec.get_height()\n",
    "        height = ax.patches[patch].get_height()\n",
    "        #print(height,height_prev[j],(height/2 + height_prev[j]))\n",
    "        ax.text(rec.get_x() + rec.get_width() / 2, (height/2 + height_prev[j]), label,\n",
    "               ha = 'center', va='bottom')\n",
    "        #print(height,height_prev[j])\n",
    "        height_prev[j] = height + height_prev[j]\n",
    "        j += 1\n",
    "        patch += 1\n",
    "\n",
    "ax.set_xticklabels(label_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X_1 = np.array(range(len(pivot_df[1]))).reshape(-1,1)\n",
    "y_1 = pivot_df[1].values\n",
    "y_2 = pivot_df[2].values\n",
    "\n",
    "X2 = sm.add_constant(X_1)\n",
    "est_1 = sm.OLS(y_1, X2)\n",
    "est_2 = sm.OLS(y_2, X2)\n",
    "est1 = est_1.fit()\n",
    "est2 = est_2.fit()\n",
    "print(est1.summary())\n",
    "print(est2.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basically, to ask the question, as more people are reporting OCD are they also getting treatment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_ocd.columns:\n",
    "    if data_ocd[column].dtypes == 'int64':\n",
    "        data_ocd[column] = data_ocd[column].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remember to sample \n",
    "\n",
    "X = data_ocd.loc[:, data_ocd.columns != 'NQ31B1']\n",
    "y = data_ocd.NQ31B1\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(solver = 'saga', penalty='l1', C=0.01)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# use the model to make predictions with the test data\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "\n",
    "print(tabulate( pd.DataFrame(sorted(zip(X_train.columns, model.coef_[0]),\n",
    "      key = lambda x:x[1],\n",
    "      reverse=True)[:15]), tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators = 2)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "\n",
    "print(tabulate(\n",
    "    pd.DataFrame( sorted(zip(X_train.columns, sel.estimator_.feature_importances_),\n",
    "      key = lambda x:x[1],\n",
    "      reverse=True)[:15]) , tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramer's V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
    "import scipy.stats as ss\n",
    "import operator\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "corDict = {}\n",
    "for col in list(data_ocd.select_dtypes(include=['category']).columns):\n",
    "    column = [col, \"NQ31B1\"]\n",
    "    temp_crammer = data_ocd[(data_ocd[col] != -1) & (~data_ocd[col].isnull())]\n",
    "    if not temp_crammer.empty:\n",
    "        confusion_matrix = pd.crosstab(temp_crammer[col], temp_crammer[\"NQ31B1\"]).as_matrix()\n",
    "        corDict[col] = cramers_v(confusion_matrix)\n",
    "    \n",
    "sorted_d = sorted(corDict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print(tabulate(pd.DataFrame(sorted_d[0:16]), tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
    "import scipy.stats as ss\n",
    "import operator\n",
    "\n",
    "def correlation_ratio(categories, measurements):\n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat)+1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    for i in range(0,cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "        #cat_measures[np.isnan(cat_measures)] = 0\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures)\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "    if numerator == 0:\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = numerator/denominator\n",
    "    return eta\n",
    "\n",
    "corDict = {}\n",
    "for col in list(data_ocd.select_dtypes(exclude=['category']).columns):\n",
    "    \n",
    "    eta = correlation_ratio(data_ocd[\"NQ31B1\"], data_ocd[col])\n",
    "    corDict[col] = eta\n",
    "    \n",
    "sorted_d = sorted(corDict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print(tabulate(pd.DataFrame(sorted_d[0:16]), tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Is there a change in the proportion of people getting treatment?</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ocd['Treated'] = 'Not Treated'\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == -1,'Treated'] = 'NA'\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == 1,'Treated'] = 'NA'\n",
    "data_ocd.loc[data_ocd['NQ31B1'] == 2,'Treated'] = 'Treated'\n",
    "\n",
    "df = data_ocd.loc[data_ocd['Treated'].isin(['Treated', 'Not Treated'])][['STUDY','Treated']]\n",
    "tab = pd.crosstab(df['Treated'], df['STUDY'])\n",
    "table = sm.stats.Table(tab)\n",
    "print(tab)\n",
    "rslt = table.test_ordinal_association()\n",
    "print(rslt.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
